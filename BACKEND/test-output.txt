[dotenv@17.2.3] injecting env (7) from .env -- tip: ΓÜÖ∩╕Å  override existing env vars with { override: true }
≡ƒº¬ Testing Groq Integration...

1∩╕ÅΓâú Testing Summary Generation...
node : Groq summary error: 
BadRequestError: 400 
{"error":{"message":"The model 
`llama-3.1-70b-versatile` has been 
decommissioned and is no longer 
supported. Please refer to https://c
onsole.groq.com/docs/deprecations 
for a recommendation on which model 
to use instead.","type":"invalid_req
uest_error","code":"model_decommissi
oned"}}
At line:1 char:1
+ node test-groq.js 2>&1 | Out-File 
-FilePath test-output.txt -Encoding 
...
+ ~~~~~~~~~~~~~~~~~~~~~~
    + CategoryInfo          : NotSp 
   ecified: (Groq summary er...com  
  missioned"}}:String) [], Remote   
 Exception
    + FullyQualifiedErrorId : Nativ 
   eCommandError
 
    at APIError.generate (D:\AI_LEAR
NING_APP\BACKEND\node_modules\groq-s
dk\error.js:40:20)
    at Groq.makeStatusError (D:\AI_L
EARNING_APP\BACKEND\node_modules\gro
q-sdk\core.js:293:33)
    at Groq.makeRequest (D:\AI_LEARN
ING_APP\BACKEND\node_modules\groq-sd
k\core.js:339:30)
    at 
process.processTicksAndRejections (n
ode:internal/process/task_queues:103
:5)
    at async generateSummary (D:\AI_
LEARNING_APP\BACKEND\services\gemini
Service.js:52:28)
    at async runTests (D:\AI_LEARNIN
G_APP\BACKEND\test-groq.js:18:25) {
  status: 400,
  headers: {
Γ£à Summary: {
  "title": "Summary Generation Failed",
  "sections": [
    {
      "heading": "Error",
      "points": [
        "Failed to generate summary: 400 {\"error\":{\"message\":\"The model `llama-3.1-70b-versatile` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.\",\"type\":\"invalid_request_error\",\"code\":\"model_decommissioned\"}}"
      ]
    }
  ],
  "keywords": [
    "error"
  ]
}
    'alt-svc': 'h3=":443"; 
ma=86400',
    'cache-control': 'private, 
max-age=0, no-store, no-cache, 
must-revalidate',
    'cf-cache-status': 'DYNAMIC',
    'cf-ray': 
'9b4eaf0d2e3b3059-MAA',
    connection: 'keep-alive',
    'content-length': '284',
    'content-type': 
'application/json',
    date: 'Sun, 28 Dec 2025 
05:33:36 GMT',
    server: 'cloudflare',
    'set-cookie': '__cf_bm=eiP7Gz43o
ZIX.FX3JoBvBLdrWLDHMdDX.wG5ulBLDh4-1
766900016-1.0.1.1-ctC5.4k4f1sxkpVOqd
7zPjr3U3wZS9zKEVn802fOiL6sU3D1IXvK1n
kMhG8KpQQbe_nZ1QeNw31lulKFgl3m0MfsO7
1tlVn90VjGVeCDxfE; path=/; 
expires=Sun, 28-Dec-25 06:03:36 
GMT; domain=.groq.com; HttpOnly; 
Secure; SameSite=None',
    'strict-transport-security': 
'max-age=15552000',
    vary: 'Origin',
    via: '1.1 google',
    'x-groq-region': 'bom',
    'x-request-id': 
'req_01kdhq592sejvrjdh7qcdt2x07'
  },
  error: {
    error: {
      message: 'The model 
`llama-3.1-70b-versatile` has been 
decommissioned and is no longer 
supported. Please refer to https://c
onsole.groq.com/docs/deprecations 
for a recommendation on which model 
to use instead.',
      type: 'invalid_request_error',
      code: 'model_decommissioned'
    }
  }
}

2∩╕ÅΓâú Testing Flashcard Generation...
Groq flashcards error: 
BadRequestError: 400 
{"error":{"message":"The model 
`llama-3.1-70b-versatile` has been 
decommissioned and is no longer 
supported. Please refer to https://c
onsole.groq.com/docs/deprecations 
for a recommendation on which model 
to use instead.","type":"invalid_req
uest_error","code":"model_decommissi
oned"}}
    at APIError.generate (D:\AI_LEAR
NING_APP\BACKEND\node_modules\groq-s
dk\error.js:40:20)
    at Groq.makeStatusError (D:\AI_L
EARNING_APP\BACKEND\node_modules\gro
q-sdk\core.js:293:33)
    at Groq.makeRequest (D:\AI_LEARN
ING_APP\BACKEND\node_modules\groq-sd
k\core.js:339:30)
    at 
process.processTicksAndRejections (n
ode:internal/process/task_queues:103
:5)
    at async generateFlashcards (D:\
AI_LEARNING_APP\BACKEND\services\gem
iniService.js:99:28)
    at async runTests (D:\AI_LEARNIN
G_APP\BACKEND\test-groq.js:23:28) {
  status: 400,
  headers: {
    'alt-svc': 'h3=":443"; 
ma=86400',
    'cache-control': 'private, 
max-age=0, no-store, no-cache, 
must-revalidate',
    'cf-cache-status': 'DYNAMIC',
    'cf-ray': 
'9b4eaf0e2fe03059-MAA',
    connection: 'keep-alive',
    'content-length': '284',
    'content-type': 
'application/json',
    date: 'Sun, 28 Dec 2025 
05:33:36 GMT',
    server: 'cloudflare',
    'set-cookie': '__cf_bm=XQNDhoIdt
hjn4sChbbeI.A0x5rTqeQ34BH6Q.tR2bYE-1
766900016-1.0.1.1-I4JYqv5NCJKQe0WjTd
QEgOJMLeycLmLqnynFRH5g6sNQqC.IfKWMMB
pE8VP6w_pP0JLQyw5Yh_kwrYKy71hVHh_hVM
Ow0aYP1A3G9KjcM7w; path=/; 
expires=Sun, 28-Dec-25 06:03:36 
GMT; domain=.groq.com; HttpOnly; 
Secure; SameSite=None',
    'strict-transport-security': 
'max-age=15552000',
    vary: 'Origin',
    via: '1.1 google',
    'x-groq-region': 'bom',
    'x-request-id': 
'req_01kdhq597gejvvh7rdbeegxtmj'
  },
  error: {
    error: {
      message: 'The model 
`llama-3.1-70b-versatile` has been 
decommissioned and is no longer 
supported. Please refer to https://c
onsole.groq.com/docs/deprecations 
for a recommendation on which model 
to use instead.',
      type: 'invalid_request_error',
      code: 'model_decommissioned'
    }
  }
}

Γ¥î TEST FAILED: Failed to generate 
flashcards: 400 
{"error":{"message":"The model 
`llama-3.1-70b-versatile` has been 
decommissioned and is no longer 
supported. Please refer to https://c
onsole.groq.com/docs/deprecations 
for a recommendation on which model 
to use instead.","type":"invalid_req
uest_error","code":"model_decommissi
oned"}}
Error: Failed to generate 
flashcards: 400 
{"error":{"message":"The model 
`llama-3.1-70b-versatile` has been 
decommissioned and is no longer 
supported. Please refer to https://c
onsole.groq.com/docs/deprecations 
for a recommendation on which model 
to use instead.","type":"invalid_req
uest_error","code":"model_decommissi
oned"}}
    at generateFlashcards (D:\AI_LEA
RNING_APP\BACKEND\services\geminiSer
vice.js:113:15)
    at 
process.processTicksAndRejections (n
ode:internal/process/task_queues:103
:5)
    at async runTests (D:\AI_LEARNIN
G_APP\BACKEND\test-groq.js:23:28)
